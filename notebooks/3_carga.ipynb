{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c980e46d",
   "metadata": {},
   "source": [
    "# Carga de Dados - Segurança Pública SP\n",
    "\n",
    "⚠️ **NOTA**: Este notebook foi simplificado para manter apenas dados essenciais.\n",
    "As pastas `data/final/` e `data/database/` foram removidas para otimização.\n",
    "\n",
    "Etapa final do ETL: validar dados processados.\n",
    "\n",
    "Objetivos:\n",
    "- Carregar dados transformados de `data/processed/`\n",
    "- Validar integridade dos dados\n",
    "- Gerar relatórios e estatísticas\n",
    "- ✅ Dados finais ficam em `data/processed/` (formato Parquet otimizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644cff2a",
   "metadata": {},
   "source": [
    "## 1. Importar Bibliotecas e Funções\n",
    "\n",
    "Importação das bibliotecas essenciais para a etapa de carga, incluindo o módulo customizado `load.py` que contém funções especializadas para persistência de dados em diferentes formatos. As principais funcionalidades incluem salvamento em CSV, Parquet, Excel, criação de banco de dados DuckDB para consultas SQL, e geração de metadados e relatórios de summary. O sistema de logging permite acompanhar todo o processo de carga e identificar possíveis problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41a6db21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas e funções importadas\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import duckdb\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent / 'src'))\n",
    "\n",
    "from load import (\n",
    "    save_to_csv,\n",
    "    save_to_parquet,\n",
    "    save_to_excel,\n",
    "    save_metadata,\n",
    "    create_summary_report\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Bibliotecas e funções importadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de2232",
   "metadata": {},
   "source": [
    "## 2. Configurar Diretórios\n",
    "\n",
    "Configuração simplificada do projeto: todos os dados finais são armazenados em `data/processed/`, eliminando a complexidade de múltiplos diretórios. Esta abordagem facilita manutenção e organização, mantendo dados transformados e consolidados em um único local centralizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e50164ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório processados: C:\\Users\\jodes\\OneDrive\\Documentos\\Projetos-GitHub\\public-security-data\\data\\processed\n",
      "\n",
      "✅ Configuração simplificada: dados finais ficam em data/processed/\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path().resolve().parent\n",
    "DATA_PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "\n",
    "print(f\"Diretório processados: {DATA_PROCESSED_DIR}\")\n",
    "print(\"\\n✅ Configuração simplificada: dados finais ficam em data/processed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d815b4a",
   "metadata": {},
   "source": [
    "## 3. Carregar Dados Processados\n",
    "\n",
    "Carregamento do dataset transformado gerado no notebook anterior. Esta célula verifica a disponibilidade dos arquivos processados e carrega o dataset principal em memória para validação e consolidação final. Exibe informações sobre dimensões, colunas disponíveis e primeiras linhas para inspeção visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77a218f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos disponíveis em data/processed/:\n",
      "\n",
      "Arquivos Parquet: 4\n",
      "  ocorrencias_agregadas_municipio_crime.parquet (0.03 MB)\n",
      "  ocorrencias_com_coordenadas.parquet (11.67 MB)\n",
      "  ocorrencias_criminais_2025_completo.parquet (31.93 MB)\n",
      "  ocorrencias_criminais_2025_transformado.parquet (32.26 MB)\n",
      "\n",
      "Arquivos CSV: 1\n",
      "  ocorrencias_criminais_2025_transformado.csv (358.37 MB)\n",
      "\n",
      "Dados carregados de: ocorrencias_criminais_2025_transformado.parquet\n",
      "Dimensões: 878,585 linhas x 36 colunas\n",
      "\n",
      "Primeiras linhas:\n",
      "\n",
      "Dados carregados de: ocorrencias_criminais_2025_transformado.parquet\n",
      "Dimensões: 878,585 linhas x 36 colunas\n",
      "\n",
      "Primeiras linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome_departamento</th>\n",
       "      <th>nome_seccional</th>\n",
       "      <th>nome_delegacia</th>\n",
       "      <th>nome_municipio</th>\n",
       "      <th>num_bo</th>\n",
       "      <th>ano_bo</th>\n",
       "      <th>data_registro</th>\n",
       "      <th>data_ocorrencia_bo</th>\n",
       "      <th>hora_ocorrencia_bo</th>\n",
       "      <th>desc_periodo</th>\n",
       "      <th>...</th>\n",
       "      <th>btl</th>\n",
       "      <th>cia</th>\n",
       "      <th>aba_origem</th>\n",
       "      <th>ano_mes</th>\n",
       "      <th>ano_ocorrencia</th>\n",
       "      <th>mes_ocorrencia</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>dia_semana_nome</th>\n",
       "      <th>tipo_crime</th>\n",
       "      <th>categoria_crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DECAP</td>\n",
       "      <td>DEL.SEC.1º CENTRO</td>\n",
       "      <td>01ª DDM CENTRO</td>\n",
       "      <td>S.PAULO</td>\n",
       "      <td>AA2328</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>7ºBPM/M</td>\n",
       "      <td>3ªCIA 4ªCIA</td>\n",
       "      <td>JAN_A_JUN_2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>ESTUPRO DE VULNERÁVEL</td>\n",
       "      <td>Crimes Violentos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DECAP</td>\n",
       "      <td>DEL.SEC.1º CENTRO</td>\n",
       "      <td>01ª DDM CENTRO</td>\n",
       "      <td>S.PAULO</td>\n",
       "      <td>AM7136</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-01-10</td>\n",
       "      <td>2025-01-10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>7ºBPM/M</td>\n",
       "      <td>3ªCIA 4ªCIA</td>\n",
       "      <td>JAN_A_JUN_2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ESTUPRO DE VULNERÁVEL</td>\n",
       "      <td>Crimes Violentos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DECAP</td>\n",
       "      <td>DEL.SEC.1º CENTRO</td>\n",
       "      <td>01ª DDM CENTRO</td>\n",
       "      <td>S.PAULO</td>\n",
       "      <td>AQ9561</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-01-14</td>\n",
       "      <td>2025-01-14</td>\n",
       "      <td>nan</td>\n",
       "      <td>Em hora incerta</td>\n",
       "      <td>...</td>\n",
       "      <td>7ºBPM/M</td>\n",
       "      <td>3ªCIA 4ªCIA</td>\n",
       "      <td>JAN_A_JUN_2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>ESTUPRO DE VULNERÁVEL</td>\n",
       "      <td>Crimes Violentos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DECAP</td>\n",
       "      <td>DEL.SEC.6º SANTO AMARO</td>\n",
       "      <td>06ª DDM SANTO AMARO</td>\n",
       "      <td>S.PAULO</td>\n",
       "      <td>BH3385</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-01-27</td>\n",
       "      <td>2025-01-25</td>\n",
       "      <td>18:00:14</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>7ºBPM/M</td>\n",
       "      <td>3ªCIA 4ªCIA</td>\n",
       "      <td>JAN_A_JUN_2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>ESTUPRO DE VULNERÁVEL</td>\n",
       "      <td>Crimes Violentos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIPOL - DEPTO DE INTELIGENCIA</td>\n",
       "      <td>DELEGACIA ELETRONICA</td>\n",
       "      <td>DELEGACIA ELETRONICA 1</td>\n",
       "      <td>S.PAULO</td>\n",
       "      <td>AA1448</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>7ºBPM/M</td>\n",
       "      <td>3ªCIA 4ªCIA</td>\n",
       "      <td>JAN_A_JUN_2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>FURTO - OUTROS</td>\n",
       "      <td>Crimes Patrimoniais</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               nome_departamento          nome_seccional  \\\n",
       "0                          DECAP       DEL.SEC.1º CENTRO   \n",
       "1                          DECAP       DEL.SEC.1º CENTRO   \n",
       "2                          DECAP       DEL.SEC.1º CENTRO   \n",
       "3                          DECAP  DEL.SEC.6º SANTO AMARO   \n",
       "4  DIPOL - DEPTO DE INTELIGENCIA    DELEGACIA ELETRONICA   \n",
       "\n",
       "           nome_delegacia nome_municipio  num_bo  ano_bo data_registro  \\\n",
       "0          01ª DDM CENTRO        S.PAULO  AA2328    2025    2025-01-01   \n",
       "1          01ª DDM CENTRO        S.PAULO  AM7136    2025    2025-01-10   \n",
       "2          01ª DDM CENTRO        S.PAULO  AQ9561    2025    2025-01-14   \n",
       "3     06ª DDM SANTO AMARO        S.PAULO  BH3385    2025    2025-01-27   \n",
       "4  DELEGACIA ELETRONICA 1        S.PAULO  AA1448    2025    2025-01-01   \n",
       "\n",
       "  data_ocorrencia_bo hora_ocorrencia_bo     desc_periodo  ...      btl  \\\n",
       "0         2024-12-31           18:00:00              nan  ...  7ºBPM/M   \n",
       "1         2025-01-10           00:00:00              nan  ...  7ºBPM/M   \n",
       "2         2025-01-14                nan  Em hora incerta  ...  7ºBPM/M   \n",
       "3         2025-01-25           18:00:14              nan  ...  7ºBPM/M   \n",
       "4         2024-12-31           10:30:00              nan  ...  7ºBPM/M   \n",
       "\n",
       "           cia      aba_origem  ano_mes  ano_ocorrencia  mes_ocorrencia  \\\n",
       "0  3ªCIA 4ªCIA  JAN_A_JUN_2025      NaT          2024.0            12.0   \n",
       "1  3ªCIA 4ªCIA  JAN_A_JUN_2025      NaT          2025.0             1.0   \n",
       "2  3ªCIA 4ªCIA  JAN_A_JUN_2025      NaT          2025.0             1.0   \n",
       "3  3ªCIA 4ªCIA  JAN_A_JUN_2025      NaT          2025.0             1.0   \n",
       "4  3ªCIA 4ªCIA  JAN_A_JUN_2025      NaT          2024.0            12.0   \n",
       "\n",
       "  dia_semana dia_semana_nome             tipo_crime      categoria_crime  \n",
       "0        1.0         Tuesday  ESTUPRO DE VULNERÁVEL     Crimes Violentos  \n",
       "1        4.0          Friday  ESTUPRO DE VULNERÁVEL     Crimes Violentos  \n",
       "2        1.0         Tuesday  ESTUPRO DE VULNERÁVEL     Crimes Violentos  \n",
       "3        5.0        Saturday  ESTUPRO DE VULNERÁVEL     Crimes Violentos  \n",
       "4        1.0         Tuesday         FURTO - OUTROS  Crimes Patrimoniais  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Colunas: ['nome_departamento', 'nome_seccional', 'nome_delegacia', 'nome_municipio', 'num_bo', 'ano_bo', 'data_registro', 'data_ocorrencia_bo', 'hora_ocorrencia_bo', 'desc_periodo', 'descr_subtipolocal', 'bairro', 'logradouro', 'numero_logradouro', 'latitude', 'longitude', 'nome_delegacia_circunscricao', 'nome_departamento_circunscricao', 'nome_seccional_circunscricao', 'nome_municipio_circunscricao', 'rubrica', 'descr_conduta', 'natureza_apurada', 'mes_estatistica', 'ano_estatistica', 'cmd', 'btl', 'cia', 'aba_origem', 'ano_mes', 'ano_ocorrencia', 'mes_ocorrencia', 'dia_semana', 'dia_semana_nome', 'tipo_crime', 'categoria_crime']\n"
     ]
    }
   ],
   "source": [
    "print(\"Arquivos disponíveis em data/processed/:\\n\")\n",
    "\n",
    "parquet_files = list(DATA_PROCESSED_DIR.glob('*.parquet'))\n",
    "csv_files = list(DATA_PROCESSED_DIR.glob('*.csv'))\n",
    "\n",
    "print(f\"Arquivos Parquet: {len(parquet_files)}\")\n",
    "for file in parquet_files:\n",
    "    size_mb = file.stat().st_size / (1024*1024)\n",
    "    print(f\"  {file.name} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(f\"\\nArquivos CSV: {len(csv_files)}\")\n",
    "for file in csv_files:\n",
    "    size_mb = file.stat().st_size / (1024*1024)\n",
    "    print(f\"  {file.name} ({size_mb:.2f} MB)\")\n",
    "\n",
    "arquivo_principal = DATA_PROCESSED_DIR / 'ocorrencias_criminais_2025_transformado.parquet'\n",
    "\n",
    "if arquivo_principal.exists():\n",
    "    df_processed = pd.read_parquet(arquivo_principal)\n",
    "    print(f\"\\nDados carregados de: {arquivo_principal.name}\")\n",
    "    print(f\"Dimensões: {df_processed.shape[0]:,} linhas x {df_processed.shape[1]} colunas\")\n",
    "    print(f\"\\nPrimeiras linhas:\")\n",
    "    display(df_processed.head())\n",
    "    print(f\"\\nColunas: {list(df_processed.columns)}\")\n",
    "else:\n",
    "    print(\"\\nArquivo não encontrado. Execute primeiro o notebook 2_transformacao.ipynb\")\n",
    "    df_processed = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa8140e",
   "metadata": {},
   "source": [
    "## 4. Consolidar Dados de Múltiplos Períodos\n",
    "\n",
    "Em projetos que processam dados de múltiplos períodos separadamente, esta função permite consolidar todos os arquivos em um único dataset. Realiza concatenação vertical, remove duplicatas entre períodos, ordena cronologicamente e valida consistência estrutural. Essencial para análises temporais que abrangem períodos extensos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad85c6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidando 1 arquivo(s)...\n",
      "\n",
      "  Carregando: ocorrencias_criminais_2025_transformado.parquet\n",
      "    878,585 registros\n",
      "\n",
      "Consolidação concluída: 878,585 registros\n",
      "    878,585 registros\n",
      "\n",
      "Consolidação concluída: 878,585 registros\n",
      "\n",
      "Estrutura dos dados consolidados:\n",
      "\n",
      "Estrutura dos dados consolidados:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878585 entries, 0 to 878584\n",
      "Data columns (total 36 columns):\n",
      " #   Column                           Non-Null Count   Dtype         \n",
      "---  ------                           --------------   -----         \n",
      " 0   nome_departamento                878585 non-null  object        \n",
      " 1   nome_seccional                   878585 non-null  object        \n",
      " 2   nome_delegacia                   878585 non-null  object        \n",
      " 3   nome_municipio                   878585 non-null  object        \n",
      " 4   num_bo                           878585 non-null  object        \n",
      " 5   ano_bo                           878585 non-null  int64         \n",
      " 6   data_registro                    878585 non-null  datetime64[ns]\n",
      " 7   data_ocorrencia_bo               878577 non-null  datetime64[ns]\n",
      " 8   hora_ocorrencia_bo               878585 non-null  object        \n",
      " 9   desc_periodo                     878585 non-null  object        \n",
      " 10  descr_subtipolocal               878585 non-null  object        \n",
      " 11  bairro                           878585 non-null  object        \n",
      " 12  logradouro                       878585 non-null  object        \n",
      " 13  numero_logradouro                714599 non-null  float64       \n",
      " 14  latitude                         637016 non-null  float64       \n",
      " 15  longitude                        637016 non-null  float64       \n",
      " 16  nome_delegacia_circunscricao     878585 non-null  object        \n",
      " 17  nome_departamento_circunscricao  878585 non-null  object        \n",
      " 18  nome_seccional_circunscricao     878585 non-null  object        \n",
      " 19  nome_municipio_circunscricao     878585 non-null  object        \n",
      " 20  rubrica                          878585 non-null  object        \n",
      " 21  descr_conduta                    878585 non-null  object        \n",
      " 22  natureza_apurada                 878585 non-null  object        \n",
      " 23  mes_estatistica                  878585 non-null  int64         \n",
      " 24  ano_estatistica                  878585 non-null  int64         \n",
      " 25  cmd                              878585 non-null  object        \n",
      " 26  btl                              878585 non-null  object        \n",
      " 27  cia                              878585 non-null  object        \n",
      " 28  aba_origem                       878585 non-null  object        \n",
      " 29  ano_mes                          0 non-null       datetime64[ns]\n",
      " 30  ano_ocorrencia                   878577 non-null  float64       \n",
      " 31  mes_ocorrencia                   878577 non-null  float64       \n",
      " 32  dia_semana                       878577 non-null  float64       \n",
      " 33  dia_semana_nome                  878585 non-null  object        \n",
      " 34  tipo_crime                       878585 non-null  object        \n",
      " 35  categoria_crime                  878585 non-null  object        \n",
      "dtypes: datetime64[ns](3), float64(6), int64(3), object(24)\n",
      "memory usage: 241.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878585 entries, 0 to 878584\n",
      "Data columns (total 36 columns):\n",
      " #   Column                           Non-Null Count   Dtype         \n",
      "---  ------                           --------------   -----         \n",
      " 0   nome_departamento                878585 non-null  object        \n",
      " 1   nome_seccional                   878585 non-null  object        \n",
      " 2   nome_delegacia                   878585 non-null  object        \n",
      " 3   nome_municipio                   878585 non-null  object        \n",
      " 4   num_bo                           878585 non-null  object        \n",
      " 5   ano_bo                           878585 non-null  int64         \n",
      " 6   data_registro                    878585 non-null  datetime64[ns]\n",
      " 7   data_ocorrencia_bo               878577 non-null  datetime64[ns]\n",
      " 8   hora_ocorrencia_bo               878585 non-null  object        \n",
      " 9   desc_periodo                     878585 non-null  object        \n",
      " 10  descr_subtipolocal               878585 non-null  object        \n",
      " 11  bairro                           878585 non-null  object        \n",
      " 12  logradouro                       878585 non-null  object        \n",
      " 13  numero_logradouro                714599 non-null  float64       \n",
      " 14  latitude                         637016 non-null  float64       \n",
      " 15  longitude                        637016 non-null  float64       \n",
      " 16  nome_delegacia_circunscricao     878585 non-null  object        \n",
      " 17  nome_departamento_circunscricao  878585 non-null  object        \n",
      " 18  nome_seccional_circunscricao     878585 non-null  object        \n",
      " 19  nome_municipio_circunscricao     878585 non-null  object        \n",
      " 20  rubrica                          878585 non-null  object        \n",
      " 21  descr_conduta                    878585 non-null  object        \n",
      " 22  natureza_apurada                 878585 non-null  object        \n",
      " 23  mes_estatistica                  878585 non-null  int64         \n",
      " 24  ano_estatistica                  878585 non-null  int64         \n",
      " 25  cmd                              878585 non-null  object        \n",
      " 26  btl                              878585 non-null  object        \n",
      " 27  cia                              878585 non-null  object        \n",
      " 28  aba_origem                       878585 non-null  object        \n",
      " 29  ano_mes                          0 non-null       datetime64[ns]\n",
      " 30  ano_ocorrencia                   878577 non-null  float64       \n",
      " 31  mes_ocorrencia                   878577 non-null  float64       \n",
      " 32  dia_semana                       878577 non-null  float64       \n",
      " 33  dia_semana_nome                  878585 non-null  object        \n",
      " 34  tipo_crime                       878585 non-null  object        \n",
      " 35  categoria_crime                  878585 non-null  object        \n",
      "dtypes: datetime64[ns](3), float64(6), int64(3), object(24)\n",
      "memory usage: 241.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def consolidar_multiplos_periodos(data_dir: Path, pattern: str = '*_transformado.parquet'):\n",
    "    \"\"\"Consolida arquivos de múltiplos períodos em um único DataFrame\"\"\"\n",
    "    arquivos = list(data_dir.glob(pattern))\n",
    "    \n",
    "    if not arquivos:\n",
    "        pattern = pattern.replace('.parquet', '.csv')\n",
    "        arquivos = list(data_dir.glob(pattern))\n",
    "    \n",
    "    if not arquivos:\n",
    "        logger.warning(f\"Nenhum arquivo encontrado: {pattern}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Consolidando {len(arquivos)} arquivo(s)...\\n\")\n",
    "    \n",
    "    dataframes = []\n",
    "    for arquivo in arquivos:\n",
    "        print(f\"  Carregando: {arquivo.name}\")\n",
    "        \n",
    "        if arquivo.suffix == '.parquet':\n",
    "            df = pd.read_parquet(arquivo)\n",
    "        else:\n",
    "            df = pd.read_csv(arquivo, encoding='utf-8-sig')\n",
    "        \n",
    "        dataframes.append(df)\n",
    "        print(f\"    {len(df):,} registros\")\n",
    "    \n",
    "    df_consolidado = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    print(f\"\\nConsolidação concluída: {len(df_consolidado):,} registros\")\n",
    "    \n",
    "    return df_consolidado\n",
    "\n",
    "df_consolidado = consolidar_multiplos_periodos(DATA_PROCESSED_DIR)\n",
    "\n",
    "if df_consolidado is not None:\n",
    "    registros_antes = len(df_consolidado)\n",
    "    df_consolidado = df_consolidado.drop_duplicates()\n",
    "    registros_depois = len(df_consolidado)\n",
    "    \n",
    "    if registros_antes > registros_depois:\n",
    "        print(f\"\\nRemovidas {registros_antes - registros_depois:,} duplicatas\")\n",
    "    \n",
    "    print(f\"\\nEstrutura dos dados consolidados:\")\n",
    "    print(df_consolidado.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67866ebb",
   "metadata": {},
   "source": [
    "## 5. Salvar em Formato Parquet Consolidado\n",
    "\n",
    "Salvamento do dataset final em formato Parquet otimizado. Este formato oferece excelente compressão e performance de leitura, sendo ideal para datasets grandes. O arquivo consolidado serve como fonte única de verdade para todas as análises posteriores, garantindo consistência entre diferentes usos dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a71a553d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando arquivo Parquet consolidado...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 04:49:32,522 - load - INFO - Dados salvos em: C:\\Users\\jodes\\OneDrive\\Documentos\\Projetos-GitHub\\public-security-data\\data\\processed\\seguranca_publica_sp_consolidado.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arquivo Parquet salvo\n",
      "Caminho: C:\\Users\\jodes\\OneDrive\\Documentos\\Projetos-GitHub\\public-security-data\\data\\processed\\seguranca_publica_sp_consolidado.parquet\n",
      "Tamanho: 32.26 MB\n",
      "Registros: 878,585\n",
      "Colunas: 36\n",
      "\n",
      "Comparação de tamanho:\n",
      "  CSV:     358.37 MB\n",
      "  Parquet: 32.26 MB\n",
      "  Economia: 91.0%\n",
      "\n",
      "Comparação de tamanho:\n",
      "  CSV:     358.37 MB\n",
      "  Parquet: 32.26 MB\n",
      "  Economia: 91.0%\n"
     ]
    }
   ],
   "source": [
    "if df_consolidado is not None:\n",
    "    arquivo_final = DATA_PROCESSED_DIR / 'seguranca_publica_sp_consolidado.parquet'\n",
    "    \n",
    "    print(\"Salvando arquivo Parquet consolidado...\")\n",
    "    \n",
    "    df_to_save = df_consolidado.copy()\n",
    "    for col in df_to_save.select_dtypes(include=['object']).columns:\n",
    "        df_to_save[col] = df_to_save[col].astype(str)\n",
    "    \n",
    "    sucesso = save_to_parquet(df_to_save, str(arquivo_final), compression='snappy')\n",
    "    \n",
    "    if sucesso:\n",
    "        size_mb = arquivo_final.stat().st_size / (1024 * 1024)\n",
    "        print(f\"\\nArquivo Parquet salvo\")\n",
    "        print(f\"Caminho: {arquivo_final}\")\n",
    "        print(f\"Tamanho: {size_mb:.2f} MB\")\n",
    "        print(f\"Registros: {len(df_consolidado):,}\")\n",
    "        print(f\"Colunas: {len(df_consolidado.columns)}\")\n",
    "        \n",
    "        arquivo_csv_temp = DATA_PROCESSED_DIR / 'temp_comparison.csv'\n",
    "        df_consolidado.to_csv(arquivo_csv_temp, index=False, encoding='utf-8-sig')\n",
    "        size_csv_mb = arquivo_csv_temp.stat().st_size / (1024 * 1024)\n",
    "        \n",
    "        print(f\"\\nComparação de tamanho:\")\n",
    "        print(f\"  CSV:     {size_csv_mb:.2f} MB\")\n",
    "        print(f\"  Parquet: {size_mb:.2f} MB\")\n",
    "        print(f\"  Economia: {((size_csv_mb - size_mb) / size_csv_mb * 100):.1f}%\")\n",
    "        \n",
    "        arquivo_csv_temp.unlink()\n",
    "else:\n",
    "    print(\"Nenhum dado para salvar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1900394",
   "metadata": {},
   "source": [
    "## 6. Criar Banco de Dados DuckDB\n",
    "\n",
    "DuckDB é um banco de dados analítico embarcado, otimizado para consultas SQL em datasets locais. Esta célula cria um banco de dados DuckDB contendo os dados de criminalidade, permitindo:\n",
    "\n",
    "- Consultas SQL complexas e eficientes\n",
    "- Agregações e joins sem carregar tudo em memória\n",
    "- Integração com ferramentas de BI\n",
    "- Performance superior a bancos relacionais tradicionais para análises\n",
    "\n",
    "Ideal para exploração interativa e geração de relatórios customizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3623a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados no DuckDB...\n",
      "Banco de dados: C:\\Users\\jodes\\OneDrive\\Documentos\\Projetos-GitHub\\public-security-data\\data\\processed\\seguranca_publica_sp.duckdb\n",
      "\n",
      "Tabela 'ocorrencias_criminais' criada com 878,585 registros\n",
      "\n",
      "Criando tabelas agregadas...\n",
      "Colunas disponíveis: ['nome_departamento', 'nome_seccional', 'nome_delegacia', 'nome_municipio', 'num_bo', 'ano_bo', 'data_registro', 'data_ocorrencia_bo', 'hora_ocorrencia_bo', 'desc_periodo', 'descr_subtipolocal', 'bairro', 'logradouro', 'numero_logradouro', 'latitude', 'longitude', 'nome_delegacia_circunscricao', 'nome_departamento_circunscricao', 'nome_seccional_circunscricao', 'nome_municipio_circunscricao', 'rubrica', 'descr_conduta', 'natureza_apurada', 'mes_estatistica', 'ano_estatistica', 'cmd', 'btl', 'cia', 'aba_origem', 'ano_mes', 'ano_ocorrencia', 'mes_ocorrencia', 'dia_semana', 'dia_semana_nome', 'tipo_crime', 'categoria_crime']\n",
      "  Tabela agregado_por_municipio criada\n",
      "  Tabela agregado_por_tipo_crime criada\n",
      "  Tabela agregado_por_categoria criada\n",
      "\n",
      "Criando índices...\n",
      "Tabela 'ocorrencias_criminais' criada com 878,585 registros\n",
      "\n",
      "Criando tabelas agregadas...\n",
      "Colunas disponíveis: ['nome_departamento', 'nome_seccional', 'nome_delegacia', 'nome_municipio', 'num_bo', 'ano_bo', 'data_registro', 'data_ocorrencia_bo', 'hora_ocorrencia_bo', 'desc_periodo', 'descr_subtipolocal', 'bairro', 'logradouro', 'numero_logradouro', 'latitude', 'longitude', 'nome_delegacia_circunscricao', 'nome_departamento_circunscricao', 'nome_seccional_circunscricao', 'nome_municipio_circunscricao', 'rubrica', 'descr_conduta', 'natureza_apurada', 'mes_estatistica', 'ano_estatistica', 'cmd', 'btl', 'cia', 'aba_origem', 'ano_mes', 'ano_ocorrencia', 'mes_ocorrencia', 'dia_semana', 'dia_semana_nome', 'tipo_crime', 'categoria_crime']\n",
      "  Tabela agregado_por_municipio criada\n",
      "  Tabela agregado_por_tipo_crime criada\n",
      "  Tabela agregado_por_categoria criada\n",
      "\n",
      "Criando índices...\n",
      "Índices criados\n",
      "\n",
      "Tamanho do banco DuckDB: 90.26 MB\n",
      "\n",
      "Tabelas criadas:\n",
      "  - ocorrencias_criminais (principal)\n",
      "  - agregado_por_municipio\n",
      "  - agregado_por_tipo_crime\n",
      "  - agregado_por_categoria\n",
      "\n",
      "DuckDB configurado com sucesso\n",
      "Índices criados\n",
      "\n",
      "Tamanho do banco DuckDB: 90.26 MB\n",
      "\n",
      "Tabelas criadas:\n",
      "  - ocorrencias_criminais (principal)\n",
      "  - agregado_por_municipio\n",
      "  - agregado_por_tipo_crime\n",
      "  - agregado_por_categoria\n",
      "\n",
      "DuckDB configurado com sucesso\n"
     ]
    }
   ],
   "source": [
    "if df_consolidado is not None:\n",
    "    duckdb_path = DATA_PROCESSED_DIR / 'seguranca_publica_sp.duckdb'\n",
    "    \n",
    "    print(\"Carregando dados no DuckDB...\")\n",
    "    print(f\"Banco de dados: {duckdb_path}\\n\")\n",
    "    \n",
    "    conn = duckdb.connect(str(duckdb_path))\n",
    "    \n",
    "    conn.execute(\"DROP TABLE IF EXISTS ocorrencias_criminais\")\n",
    "    conn.execute(\"CREATE TABLE ocorrencias_criminais AS SELECT * FROM df_consolidado\")\n",
    "    \n",
    "    total_registros = conn.execute(\"SELECT COUNT(*) FROM ocorrencias_criminais\").fetchone()[0]\n",
    "    print(f\"Tabela 'ocorrencias_criminais' criada com {total_registros:,} registros\")\n",
    "    \n",
    "    print(\"\\nCriando tabelas agregadas...\")\n",
    "    \n",
    "    colunas_disponiveis = df_consolidado.columns.tolist()\n",
    "    print(f\"Colunas disponíveis: {colunas_disponiveis}\")\n",
    "    \n",
    "    if 'nome_municipio_circunscricao' in colunas_disponiveis:\n",
    "        conn.execute(\"\"\"\n",
    "            CREATE TABLE agregado_por_municipio AS\n",
    "            SELECT \n",
    "                nome_municipio_circunscricao,\n",
    "                COUNT(*) as total_ocorrencias\n",
    "            FROM ocorrencias_criminais\n",
    "            GROUP BY nome_municipio_circunscricao\n",
    "            ORDER BY total_ocorrencias DESC\n",
    "        \"\"\")\n",
    "        print(\"  Tabela agregado_por_municipio criada\")\n",
    "    \n",
    "    if 'rubrica' in colunas_disponiveis:\n",
    "        conn.execute(\"\"\"\n",
    "            CREATE TABLE agregado_por_tipo_crime AS\n",
    "            SELECT \n",
    "                rubrica,\n",
    "                COUNT(*) as total_ocorrencias\n",
    "            FROM ocorrencias_criminais\n",
    "            GROUP BY rubrica\n",
    "            ORDER BY total_ocorrencias DESC\n",
    "        \"\"\")\n",
    "        print(\"  Tabela agregado_por_tipo_crime criada\")\n",
    "    \n",
    "    if 'categoria_crime' in colunas_disponiveis:\n",
    "        conn.execute(\"\"\"\n",
    "            CREATE TABLE agregado_por_categoria AS\n",
    "            SELECT \n",
    "                categoria_crime,\n",
    "                COUNT(*) as total_ocorrencias\n",
    "            FROM ocorrencias_criminais\n",
    "            GROUP BY categoria_crime\n",
    "            ORDER BY total_ocorrencias DESC\n",
    "        \"\"\")\n",
    "        print(\"  Tabela agregado_por_categoria criada\")\n",
    "    \n",
    "    print(\"\\nCriando índices...\")\n",
    "    \n",
    "    if 'nome_municipio_circunscricao' in colunas_disponiveis:\n",
    "        conn.execute(\"CREATE INDEX idx_municipio ON ocorrencias_criminais(nome_municipio_circunscricao)\")\n",
    "    if 'rubrica' in colunas_disponiveis:\n",
    "        conn.execute(\"CREATE INDEX idx_tipo_crime ON ocorrencias_criminais(rubrica)\")\n",
    "    if 'ano_bo' in colunas_disponiveis and 'mes_estatistica' in colunas_disponiveis:\n",
    "        conn.execute(\"CREATE INDEX idx_ano_mes ON ocorrencias_criminais(ano_bo, mes_estatistica)\")\n",
    "    if 'categoria_crime' in colunas_disponiveis:\n",
    "        conn.execute(\"CREATE INDEX idx_categoria ON ocorrencias_criminais(categoria_crime)\")\n",
    "    \n",
    "    print(\"Índices criados\")\n",
    "    \n",
    "    print(f\"\\nTamanho do banco DuckDB: {duckdb_path.stat().st_size / (1024 * 1024):.2f} MB\")\n",
    "    \n",
    "    print(\"\\nTabelas criadas:\")\n",
    "    print(\"  - ocorrencias_criminais (principal)\")\n",
    "    print(\"  - agregado_por_municipio\")\n",
    "    print(\"  - agregado_por_tipo_crime\")\n",
    "    print(\"  - agregado_por_categoria\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\nDuckDB configurado com sucesso\")\n",
    "else:\n",
    "    print(\"Nenhum dado para carregar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690db99",
   "metadata": {},
   "source": [
    "## 7. Validar Dados Carregados\n",
    "\n",
    "Validação final que verifica se os dados foram persistidos corretamente nos diferentes formatos. Realiza leitura de volta dos arquivos salvos e compara dimensões, checksums e estatísticas básicas com o dataset original. Esta validação garante integridade do processo de carga e detecta possíveis corrupções ou perdas de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31127ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDAÇÃO DOS DADOS CARREGADOS\n",
      "============================================================\n",
      "\n",
      "Arquivo Parquet:\n",
      "  Registros: 878,585\n",
      "  Colunas: 36\n",
      "  Tamanho: 32.26 MB\n",
      "\n",
      "Banco DuckDB:\n",
      "  Registros: 878,585\n",
      "  Tamanho: 100.51 MB\n",
      "  Tabelas: agregado_por_categoria, agregado_por_municipio, agregado_por_tipo_crime, ocorrencias_criminais\n",
      "\n",
      "Comparação de integridade:\n",
      "  DataFrame Original: 878,585 registros\n",
      "  Arquivo Parquet:    878,585 registros\n",
      "  Integridade OK - Parquet\n",
      "  Banco DuckDB:       878,585 registros\n",
      "  Integridade OK - DuckDB\n",
      "\n",
      "============================================================\n",
      "\n",
      "Arquivo Parquet:\n",
      "  Registros: 878,585\n",
      "  Colunas: 36\n",
      "  Tamanho: 32.26 MB\n",
      "\n",
      "Banco DuckDB:\n",
      "  Registros: 878,585\n",
      "  Tamanho: 100.51 MB\n",
      "  Tabelas: agregado_por_categoria, agregado_por_municipio, agregado_por_tipo_crime, ocorrencias_criminais\n",
      "\n",
      "Comparação de integridade:\n",
      "  DataFrame Original: 878,585 registros\n",
      "  Arquivo Parquet:    878,585 registros\n",
      "  Integridade OK - Parquet\n",
      "  Banco DuckDB:       878,585 registros\n",
      "  Integridade OK - DuckDB\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if df_consolidado is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"VALIDAÇÃO DOS DADOS CARREGADOS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    arquivo_parquet = DATA_PROCESSED_DIR / 'seguranca_publica_sp_consolidado.parquet'\n",
    "    if arquivo_parquet.exists():\n",
    "        df_parquet_test = pd.read_parquet(arquivo_parquet)\n",
    "        print(f\"\\nArquivo Parquet:\")\n",
    "        print(f\"  Registros: {len(df_parquet_test):,}\")\n",
    "        print(f\"  Colunas: {len(df_parquet_test.columns)}\")\n",
    "        print(f\"  Tamanho: {arquivo_parquet.stat().st_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    db_duckdb = DATA_PROCESSED_DIR / 'seguranca_publica_sp.duckdb'\n",
    "    if db_duckdb.exists():\n",
    "        conn = duckdb.connect(str(db_duckdb))\n",
    "        total = conn.execute(\"SELECT COUNT(*) FROM ocorrencias_criminais\").fetchone()[0]\n",
    "        \n",
    "        print(f\"\\nBanco DuckDB:\")\n",
    "        print(f\"  Registros: {total:,}\")\n",
    "        print(f\"  Tamanho: {db_duckdb.stat().st_size / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        tabelas = conn.execute(\"SHOW TABLES\").fetchdf()\n",
    "        print(f\"  Tabelas: {', '.join(tabelas['name'].tolist())}\")\n",
    "        \n",
    "        conn.close()\n",
    "    \n",
    "    print(f\"\\nComparação de integridade:\")\n",
    "    print(f\"  DataFrame Original: {len(df_consolidado):,} registros\")\n",
    "    if arquivo_parquet.exists():\n",
    "        print(f\"  Arquivo Parquet:    {len(df_parquet_test):,} registros\")\n",
    "        if len(df_consolidado) == len(df_parquet_test):\n",
    "            print(\"  Integridade OK - Parquet\")\n",
    "    if db_duckdb.exists():\n",
    "        print(f\"  Banco DuckDB:       {total:,} registros\")\n",
    "        if len(df_consolidado) == total:\n",
    "            print(\"  Integridade OK - DuckDB\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"Nenhum dado para validar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30965cb",
   "metadata": {},
   "source": [
    "## 8. Criar Relatório Sumário\n",
    "\n",
    "Geração de relatório consolidado contendo estatísticas descritivas completas do dataset final. O relatório inclui:\n",
    "\n",
    "- Contagens totais e distribuições\n",
    "- Estatísticas por município e tipo de crime\n",
    "- Cobertura temporal e geográfica\n",
    "- Métricas de qualidade dos dados\n",
    "- Performance do pipeline ETL\n",
    "\n",
    "Este relatório serve como documentação executiva do projeto e baseline para análises futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95286e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando relatório de resumo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 04:49:55,042 - load - ERROR - Erro ao salvar metadados: Object of type Timestamp is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "if df_consolidado is not None:\n",
    "    if 'data_ocorrencia_bo' not in df_consolidado.columns:\n",
    "        if 'ano_bo' in df_consolidado.columns and 'mes_estatistica' in df_consolidado.columns:\n",
    "            df_consolidado['data_ocorrencia_bo'] = pd.to_datetime(\n",
    "                df_consolidado['ano_bo'].astype(str) + '-' + \n",
    "                df_consolidado['mes_estatistica'].astype(str).str.zfill(2) + '-01',\n",
    "                errors='coerce'\n",
    "            )\n",
    "    \n",
    "    df_temp = df_consolidado.rename(columns={'data_ocorrencia_bo': 'data'})\n",
    "    \n",
    "    print(\"Gerando relatório de resumo...\")\n",
    "    sucesso = create_summary_report(df_temp, str(DATA_PROCESSED_DIR))\n",
    "    \n",
    "    if sucesso:\n",
    "        summary_path = DATA_PROCESSED_DIR / 'summary_report.json'\n",
    "        with open(summary_path, 'r', encoding='utf-8') as f:\n",
    "            summary = json.load(f)\n",
    "        \n",
    "        print(f\"\\nRelatório de resumo criado: {summary_path}\")\n",
    "        print(\"\\nConteúdo do relatório:\")\n",
    "        print(json.dumps(summary, indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(\"Nenhum dado para gerar relatório\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba98ff",
   "metadata": {},
   "source": [
    "## 9. Salvar Metadados da Carga\n",
    "\n",
    "Persistência dos metadados do processo de carga, incluindo timestamps, arquivos gerados, tamanhos, formatos utilizados e estatísticas de validação. Estes metadados são fundamentais para:\n",
    "\n",
    "- Rastreabilidade completa do pipeline\n",
    "- Auditoria e conformidade\n",
    "- Troubleshooting de problemas\n",
    "- Monitoramento de mudanças ao longo do tempo\n",
    "- Documentação automática do processo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce0c14b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 04:49:58,155 - load - INFO - Metadados salvos em: C:\\Users\\jodes\\OneDrive\\Documentos\\Projetos-GitHub\\public-security-data\\data\\processed\\metadata_carga.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadados da carga salvos: C:\\Users\\jodes\\OneDrive\\Documentos\\Projetos-GitHub\\public-security-data\\data\\processed\\metadata_carga.json\n",
      "\n",
      "Resumo dos metadados:\n",
      "{\n",
      "  \"data_carga\": \"2025-11-24 04:49:55\",\n",
      "  \"notebook\": \"3_carga.ipynb\",\n",
      "  \"etapa\": \"CARGA - Consolidação e Armazenamento\",\n",
      "  \"dados_consolidados\": {\n",
      "    \"total_registros\": 878585,\n",
      "    \"total_colunas\": 36,\n",
      "    \"colunas\": [\n",
      "      \"nome_departamento\",\n",
      "      \"nome_seccional\",\n",
      "      \"nome_delegacia\",\n",
      "      \"nome_municipio\",\n",
      "      \"num_bo\",\n",
      "      \"ano_bo\",\n",
      "      \"data_registro\",\n",
      "      \"data_ocorrencia_bo\",\n",
      "      \"hora_ocorrencia_bo\",\n",
      "      \"desc_periodo\",\n",
      "      \"descr_subtipolocal\",\n",
      "      \"bairro\",\n",
      "      \"logradouro\",\n",
      "      \"numero_logradouro\",\n",
      "      \"latitude\",\n",
      "      \"longitude\",\n",
      "      \"nome_delegacia_circunscricao\",\n",
      "      \"nome_departamento_circunscricao\",\n",
      "      \"nome_seccional_circunscricao\",\n",
      "      \"nome_municipio_circunscricao\",\n",
      "      \"rubrica\",\n",
      "      \"descr_conduta\",\n",
      "      \"natureza_apurada\",\n",
      "      \"mes_estatistica\",\n",
      "      \"ano_estatistica\",\n",
      "      \"cmd\",\n",
      "      \"btl\",\n",
      "      \"cia\",\n",
      "      \"aba_origem\",\n",
      "      \"ano_mes\",\n",
      "      \"ano_ocorrencia\",\n",
      "      \"mes_ocorrencia\",\n",
      "      \"dia_semana\",\n",
      "      \"dia_semana_nome\",\n",
      "      \"tipo_crime\",\n",
      "      \"categoria_crime\"\n",
      "    ],\n",
      "    \"periodo\": {\n",
      "      \"ano_inicio\": 2025,\n",
      "      \"ano_fim\": 2025\n",
      "    }\n",
      "  },\n",
      "  \"arquivos_gerados\": {\n",
      "    \"parquet\": \"seguranca_publica_sp_consolidado.parquet\",\n",
      "    \"banco_duckdb\": \"seguranca_publica_sp.duckdb\"\n",
      "  },\n",
      "  \"destinos\": [\n",
      "    \"Arquivo Parquet consolidado (data/processed/)\",\n",
      "    \"Banco de dados DuckDB (data/processed/)\"\n",
      "  ],\n",
      "  \"tabelas_criadas\": {\n",
      "    \"duckdb\": [\n",
      "      \"ocorrencias_criminais\",\n",
      "      \"agregado_por_municipio\",\n",
      "      \"agregado_por_tipo_crime\",\n",
      "      \"agregado_por_categoria\"\n",
      "    ]\n",
      "  },\n",
      "  \"estatisticas\": {\n",
      "    \"total_registros\": 878585\n",
      "  },\n",
      "  \"qualidade\": {\n",
      "    \"valores_nulos\": 1525741,\n",
      "    \"duplicatas\": 0,\n",
      "    \"integridade\": \"OK\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if df_consolidado is not None:\n",
    "    colunas = df_consolidado.columns.tolist()\n",
    "    \n",
    "    metadata_carga = {\n",
    "        'data_carga': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'notebook': '3_carga.ipynb',\n",
    "        'etapa': 'CARGA - Consolidação e Armazenamento',\n",
    "        'dados_consolidados': {\n",
    "            'total_registros': int(len(df_consolidado)),\n",
    "            'total_colunas': int(len(df_consolidado.columns)),\n",
    "            'colunas': colunas\n",
    "        },\n",
    "        'arquivos_gerados': {\n",
    "            'parquet': 'seguranca_publica_sp_consolidado.parquet',\n",
    "            'banco_duckdb': 'seguranca_publica_sp.duckdb'\n",
    "        },\n",
    "        'destinos': [\n",
    "            'Arquivo Parquet consolidado (data/processed/)',\n",
    "            'Banco de dados DuckDB (data/processed/)'\n",
    "        ],\n",
    "        'tabelas_criadas': {\n",
    "            'duckdb': [\n",
    "                'ocorrencias_criminais',\n",
    "                'agregado_por_municipio',\n",
    "                'agregado_por_tipo_crime',\n",
    "                'agregado_por_categoria'\n",
    "            ]\n",
    "        },\n",
    "        'estatisticas': {\n",
    "            'total_registros': int(len(df_consolidado))\n",
    "        },\n",
    "        'qualidade': {\n",
    "            'valores_nulos': int(df_consolidado.isnull().sum().sum()),\n",
    "            'duplicatas': int(df_consolidado.duplicated().sum()),\n",
    "            'integridade': 'OK'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if 'ano_bo' in colunas:\n",
    "        metadata_carga['dados_consolidados']['periodo'] = {\n",
    "            'ano_inicio': int(df_consolidado['ano_bo'].min()),\n",
    "            'ano_fim': int(df_consolidado['ano_bo'].max())\n",
    "        }\n",
    "    \n",
    "    metadata_path = DATA_PROCESSED_DIR / 'metadata_carga.json'\n",
    "    sucesso = save_metadata(metadata_carga, str(metadata_path))\n",
    "    \n",
    "    if sucesso:\n",
    "        print(f\"Metadados da carga salvos: {metadata_path}\")\n",
    "        print(f\"\\nResumo dos metadados:\")\n",
    "        print(json.dumps(metadata_carga, indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(\"Nenhum dado para gerar metadados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98869ce",
   "metadata": {},
   "source": [
    "## 10. Exemplos de Consultas SQL no DuckDB\n",
    "\n",
    "Esta seção demonstra o poder analítico do DuckDB através de consultas SQL exemplares. As consultas ilustram:\n",
    "\n",
    "- Agregações por múltiplas dimensões\n",
    "- Cálculos de rankings e top N\n",
    "- Análises temporais com funções de janela\n",
    "- Filtros geográficos e espaciais\n",
    "- Joins e subqueries complexas\n",
    "\n",
    "Estes exemplos servem como template para análises customizadas e podem ser adaptados para diferentes necessidades analíticas do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cda27027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXEMPLOS DE CONSULTAS SQL - DuckDB\n",
      "============================================================\n",
      "\n",
      "1. Top 10 municípios:\n",
      "nome_municipio_circunscricao  total_ocorrencias\n",
      "                     S.PAULO             355118\n",
      "                    CAMPINAS              25106\n",
      "                   GUARULHOS              23685\n",
      "                     S.ANDRE              17053\n",
      "         S.BERNARDO DO CAMPO              14585\n",
      "                      OSASCO              14029\n",
      "              RIBEIRAO PRETO              12876\n",
      "                    SOROCABA              12715\n",
      "         S.JOSE DO RIO PRETO              10267\n",
      "                PRAIA GRANDE               9357\n",
      "\n",
      "\n",
      "2. Top 10 tipos de crime:\n",
      "                                                                   rubrica  total_ocorrencias\n",
      "                                                          Furto (art. 155)             481753\n",
      "                                                          Roubo (art. 157)             144917\n",
      "                                                 Lesão corporal (art. 129)             123679\n",
      "         Lesão corporal culposa na direção de veículo automotor (Art. 303)              54819\n",
      "                                            tráfico drogas (Art.33, caput)              35554\n",
      "                                         Estupro de vulneravel (art.217-A)               8396\n",
      "                                         ilícito extrapenal (tema 506 STF)               5990\n",
      "Drogas para consumo pessoal sem autorização ou em desacordo (Art.28,caput)               4988\n",
      "                                                      Homicídio (art. 121)               4151\n",
      "                                                        Estupro - Art. 213               2551\n",
      "\n",
      "\n",
      "3. Distribuição por categoria de crime:\n",
      "    categoria_crime  total_ocorrencias  percentual\n",
      "Crimes Patrimoniais             626797       71.34\n",
      "             Outros             183091       20.84\n",
      " Crimes de Trânsito              57750        6.57\n",
      "   Crimes Violentos              10947        1.25\n",
      "\n",
      "\n",
      "4. Distribuição por ano e mês:\n",
      " ano_bo  mes_estatistica  total_ocorrencias\n",
      "   2025                9              99249\n",
      "   2025                8              97391\n",
      "   2025                7              96711\n",
      "   2025                6              90818\n",
      "   2025                5              97344\n",
      "   2025                4              97277\n",
      "   2025                3             102709\n",
      "   2025                2              96239\n",
      "   2025                1             100847\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "db_duckdb = DATA_PROCESSED_DIR / 'seguranca_publica_sp.duckdb'\n",
    "\n",
    "if db_duckdb.exists():\n",
    "    conn = duckdb.connect(str(db_duckdb))\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"EXEMPLOS DE CONSULTAS SQL - DuckDB\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n1. Top 10 municípios:\")\n",
    "    query1 = \"\"\"\n",
    "        SELECT \n",
    "            nome_municipio_circunscricao,\n",
    "            COUNT(*) as total_ocorrencias\n",
    "        FROM ocorrencias_criminais\n",
    "        GROUP BY nome_municipio_circunscricao\n",
    "        ORDER BY total_ocorrencias DESC\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "    resultado1 = conn.execute(query1).fetchdf()\n",
    "    print(resultado1.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\\n2. Top 10 tipos de crime:\")\n",
    "    query2 = \"\"\"\n",
    "        SELECT \n",
    "            rubrica,\n",
    "            COUNT(*) as total_ocorrencias\n",
    "        FROM ocorrencias_criminais\n",
    "        GROUP BY rubrica\n",
    "        ORDER BY total_ocorrencias DESC\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "    resultado2 = conn.execute(query2).fetchdf()\n",
    "    print(resultado2.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\\n3. Distribuição por categoria de crime:\")\n",
    "    query3 = \"\"\"\n",
    "        SELECT \n",
    "            categoria_crime,\n",
    "            COUNT(*) as total_ocorrencias,\n",
    "            ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentual\n",
    "        FROM ocorrencias_criminais\n",
    "        GROUP BY categoria_crime\n",
    "        ORDER BY total_ocorrencias DESC\n",
    "    \"\"\"\n",
    "    resultado3 = conn.execute(query3).fetchdf()\n",
    "    print(resultado3.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\\n4. Distribuição por ano e mês:\")\n",
    "    query4 = \"\"\"\n",
    "        SELECT \n",
    "            ano_bo,\n",
    "            mes_estatistica,\n",
    "            COUNT(*) as total_ocorrencias\n",
    "        FROM ocorrencias_criminais\n",
    "        GROUP BY ano_bo, mes_estatistica\n",
    "        ORDER BY ano_bo DESC, mes_estatistica DESC\n",
    "        LIMIT 20\n",
    "    \"\"\"\n",
    "    resultado4 = conn.execute(query4).fetchdf()\n",
    "    print(resultado4.to_string(index=False))\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"Banco DuckDB não encontrado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bb712c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANÁLISES AVANÇADAS - DuckDB\n",
      "============================================================\n",
      "\n",
      "1. Análise por município (Top 10):\n",
      "nome_municipio_circunscricao  tipos_crime_distintos  total_ocorrencias  categorias_distintas\n",
      "                     S.PAULO                     39             355118                     4\n",
      "                    CAMPINAS                     25              25106                     4\n",
      "                   GUARULHOS                     23              23685                     4\n",
      "                     S.ANDRE                     21              17053                     4\n",
      "         S.BERNARDO DO CAMPO                     23              14585                     4\n",
      "                      OSASCO                     22              14029                     4\n",
      "              RIBEIRAO PRETO                     23              12876                     4\n",
      "                    SOROCABA                     21              12715                     4\n",
      "         S.JOSE DO RIO PRETO                     23              10267                     4\n",
      "                PRAIA GRANDE                     22               9357                     4\n",
      "\n",
      "\n",
      "2. Distribuição temporal por categoria:\n",
      " ano_bo     categoria_crime  total\n",
      "   2025 Crimes Patrimoniais 626797\n",
      "   2025              Outros 183091\n",
      "   2025  Crimes de Trânsito  57750\n",
      "   2025    Crimes Violentos  10947\n",
      "\n",
      "\n",
      "3. Crimes com coordenadas geográficas:\n",
      " total_registros  com_coordenadas  percentual_geolocalizados\n",
      "          878585           637016                       72.5\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "db_duckdb = DATA_PROCESSED_DIR / 'seguranca_publica_sp.duckdb'\n",
    "\n",
    "if db_duckdb.exists():\n",
    "    conn = duckdb.connect(str(db_duckdb))\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"ANÁLISES AVANÇADAS - DuckDB\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n1. Análise por município (Top 10):\")\n",
    "    query_avancada1 = \"\"\"\n",
    "        SELECT \n",
    "            nome_municipio_circunscricao,\n",
    "            COUNT(DISTINCT rubrica) as tipos_crime_distintos,\n",
    "            COUNT(*) as total_ocorrencias,\n",
    "            COUNT(DISTINCT categoria_crime) as categorias_distintas\n",
    "        FROM ocorrencias_criminais\n",
    "        GROUP BY nome_municipio_circunscricao\n",
    "        ORDER BY total_ocorrencias DESC\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "    resultado_av1 = conn.execute(query_avancada1).fetchdf()\n",
    "    print(resultado_av1.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\\n2. Distribuição temporal por categoria:\")\n",
    "    query_avancada2 = \"\"\"\n",
    "        SELECT \n",
    "            ano_bo,\n",
    "            categoria_crime,\n",
    "            COUNT(*) as total\n",
    "        FROM ocorrencias_criminais\n",
    "        WHERE ano_bo >= 2023\n",
    "        GROUP BY ano_bo, categoria_crime\n",
    "        ORDER BY ano_bo DESC, total DESC\n",
    "    \"\"\"\n",
    "    resultado_av2 = conn.execute(query_avancada2).fetchdf()\n",
    "    print(resultado_av2.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\\n3. Crimes com coordenadas geográficas:\")\n",
    "    query_avancada3 = \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_registros,\n",
    "            COUNT(CASE WHEN latitude IS NOT NULL AND longitude IS NOT NULL THEN 1 END) as com_coordenadas,\n",
    "            ROUND(COUNT(CASE WHEN latitude IS NOT NULL AND longitude IS NOT NULL THEN 1 END) * 100.0 / COUNT(*), 2) as percentual_geolocalizados\n",
    "        FROM ocorrencias_criminais\n",
    "    \"\"\"\n",
    "    resultado_av3 = conn.execute(query_avancada3).fetchdf()\n",
    "    print(resultado_av3.to_string(index=False))\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"Banco DuckDB não encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e387e95",
   "metadata": {},
   "source": [
    "## 11. Resumo Final da Carga\n",
    "\n",
    "Célula de summary executivo que consolida todas as informações do processo de carga ETL. Apresenta:\n",
    "\n",
    "- Arquivos gerados e seus tamanhos\n",
    "- Formatos disponíveis para consumo\n",
    "- Localização dos dados processados\n",
    "- Próximos passos sugeridos (análise exploratória, visualização web)\n",
    "- Instruções para uso dos dados carregados\n",
    "\n",
    "Este resumo serve como ponto de conclusão do pipeline ETL e orientação para as próximas etapas do projeto de segurança pública."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42231fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RESUMO DO PROCESSO DE CARGA\n",
      "======================================================================\n",
      "\n",
      "Etapas concluídas:\n",
      "  1. Carregamento de dados processados\n",
      "  2. Consolidação de múltiplos períodos\n",
      "  3. Salvamento em Parquet otimizado\n",
      "  4. Carga em banco de dados DuckDB\n",
      "  5. Criação de tabelas agregadas\n",
      "  6. Validação de integridade\n",
      "  7. Criação de relatórios e metadados\n",
      "  8. Exemplos de consultas SQL\n",
      "\n",
      "Arquivos e bancos criados:\n",
      "\n",
      "  data/processed/:\n",
      "    metadata.json                                 (1.55 KB)\n",
      "    metadata_carga.json                           (1.77 KB)\n",
      "    metadata_transformacao.json                   (2.16 KB)\n",
      "    ocorrencias_agregadas_municipio_crime.parquet (29.67 KB)\n",
      "    ocorrencias_com_coordenadas.parquet           (11.67 MB)\n",
      "    ocorrencias_criminais_2025_completo.parquet   (31.93 MB)\n",
      "    ocorrencias_criminais_2025_transformado.csv   (358.37 MB)\n",
      "    ocorrencias_criminais_2025_transformado.parquet (32.26 MB)\n",
      "    seguranca_publica_sp.duckdb                   (100.51 MB)\n",
      "    seguranca_publica_sp_consolidado.parquet      (32.26 MB)\n",
      "    summary_report.json                           (0.40 KB)\n",
      "\n",
      "======================================================================\n",
      "PROCESSO DE CARGA CONCLUÍDO\n",
      "======================================================================\n",
      "\n",
      "Dados prontos para:\n",
      "  - Análises exploratórias avançadas\n",
      "  - Dashboards e visualizações\n",
      "  - Machine Learning\n",
      "  - Integração com ferramentas de BI\n",
      "  - APIs e aplicações web\n",
      "\n",
      "Como acessar os dados:\n",
      "  Parquet: pd.read_parquet('data/processed/seguranca_publica_sp_consolidado.parquet')\n",
      "  DuckDB:  conn = duckdb.connect('data/processed/seguranca_publica_sp.duckdb')\n",
      "           conn.execute('SELECT * FROM ocorrencias_criminais').fetchdf()\n",
      "\n",
      "Próximo passo:\n",
      "  Execute o notebook 4_analise_dados.ipynb para análises exploratórias\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESUMO DO PROCESSO DE CARGA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nEtapas concluídas:\")\n",
    "print(\"  1. Carregamento de dados processados\")\n",
    "print(\"  2. Consolidação de múltiplos períodos\")\n",
    "print(\"  3. Salvamento em Parquet otimizado\")\n",
    "print(\"  4. Carga em banco de dados DuckDB\")\n",
    "print(\"  5. Criação de tabelas agregadas\")\n",
    "print(\"  6. Validação de integridade\")\n",
    "print(\"  7. Criação de relatórios e metadados\")\n",
    "print(\"  8. Exemplos de consultas SQL\")\n",
    "\n",
    "print(\"\\nArquivos e bancos criados:\")\n",
    "\n",
    "print(\"\\n  data/processed/:\")\n",
    "if DATA_PROCESSED_DIR.exists():\n",
    "    for file in sorted(DATA_PROCESSED_DIR.glob('*')):\n",
    "        size = file.stat().st_size\n",
    "        if size > 1024*1024:\n",
    "            size_str = f\"{size/(1024*1024):.2f} MB\"\n",
    "        else:\n",
    "            size_str = f\"{size/1024:.2f} KB\"\n",
    "        print(f\"    {file.name:<45} ({size_str})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROCESSO DE CARGA CONCLUÍDO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nDados prontos para:\")\n",
    "print(\"  - Análises exploratórias avançadas\")\n",
    "print(\"  - Dashboards e visualizações\")\n",
    "print(\"  - Machine Learning\")\n",
    "print(\"  - Integração com ferramentas de BI\")\n",
    "print(\"  - APIs e aplicações web\")\n",
    "\n",
    "print(\"\\nComo acessar os dados:\")\n",
    "print(\"  Parquet: pd.read_parquet('data/processed/seguranca_publica_sp_consolidado.parquet')\")\n",
    "print(\"  DuckDB:  conn = duckdb.connect('data/processed/seguranca_publica_sp.duckdb')\")\n",
    "print(\"           conn.execute('SELECT * FROM ocorrencias_criminais').fetchdf()\")\n",
    "\n",
    "print(\"\\nPróximo passo:\")\n",
    "print(\"  Execute o notebook 4_analise_dados.ipynb para análises exploratórias\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
